{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text processing pipeline \n",
    "import nltk\n",
    "text1 = ''' Natural language processing (NLP) is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods. In 1950, Alan Turing published an article titled \"Computing Machinery and Intelligence\" which proposed what is now called the Turing test as a criterion of intelligence\n",
    "'''\n",
    "\n",
    "for text in text1 :\n",
    "    sentences =  nltk.sent_tokenize(text1)\n",
    "    for sentence in sentences: \n",
    "        words =  nltk.word_tokenize(sentence)\n",
    "        tagged = nltk.pos_tag(words)\n",
    "        print(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Tweet tokenizer \n",
    "\n",
    "from nltk.tokenize import TweetTokenizer \n",
    "text = 'The party was sooo fun :D #superfun'\n",
    "\n",
    "twtkn = TweetTokenizer()\n",
    "twtkn.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Scarping data from web \n",
    "from urllib import request \n",
    "url = \" http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "response = request.urlopen(url)\n",
    "raw = response.read().decode('utf8')\n",
    "type(raw)\n",
    "len(raw)\n",
    "raw[:75]\n",
    "from nltk.tokenize import word_tokenize\n",
    "tokens = word_tokenize(raw)\n",
    "type(tokens)\n",
    "#html=>ASCII=> TEXT => VOCAB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. HANDLING TWEET DATA \n",
    "import nltk\n",
    "f = open('tweets1.txt','r')\n",
    "text = f.read()\n",
    "text1 = text.split()\n",
    "text2 = ntlk.Text(text1)\n",
    "text2.concordance(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. HANDLING TWEET DATA \n",
    "import nltk\n",
    "f = open('tweets1.txt','r')\n",
    "text = f.read()\n",
    "text1 = text.split()\n",
    "text2 = nltk.Text(text1)\n",
    "text2.concordance(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
